    - uses: actions/checkout@v3

    - uses: aws-actions/configure-aws-credentials@v2
      with:
        role-to-assume: "${{ secrets.AWS_ROLE_ARN }}"
        aws-region:     "${{ env.AWS_DEFAULT_REGION }}"

    - name: Who am I?
      run: aws sts get-caller-identity

    - name: Ensure ECR repos
      run: |
        for repo in "$ECR_REPO" sklearn-inference ; do
          aws ecr describe-repositories --repository-names "$repo" ||
          aws ecr create-repository --repository-name "$repo"
        done

    - name: Build & push APP image
      env: { DOCKER_BUILDKIT: 1 }
      run: |
        docker build --platform linux/amd64 -t $ECR_REPO:${{ github.sha }} ./app
        docker tag  $ECR_REPO:${{ github.sha }} \
          $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$ECR_REPO:${{ github.sha }}
        aws ecr get-login-password --region $AWS_DEFAULT_REGION | \
          docker login -u AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
        docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$ECR_REPO:${{ github.sha }}

    - name: Upload model artefact
      run: aws s3 cp ml_model/models/model.tar.gz "$MODEL_S3_PATH"

    - name: Install kubectl
      run: |
        curl -sSL https://dl.k8s.io/release/$(curl -sSL https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl -o kubectl
        chmod +x kubectl && sudo mv kubectl /usr/local/bin

    - name: Configure kubeconfig
      run: |
        aws eks update-kubeconfig --region $AWS_DEFAULT_REGION --name "${{ secrets.EKS_CLUSTER_NAME }}"
        kubectl get nodes

    - name: Bootstrap objects once
      run: kubectl apply -f kubernetes/bootstrap.yaml || true

    - uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install Python deps
      run: |
        if [[ -f requirements.txt ]]; then pip install -r requirements.txt; fi
        pip install requests pytest

    - name: Export PYTHONPATH for tests
      run: echo "PYTHONPATH=${{ github.workspace }}" >> $GITHUB_ENV

    # Ensure tools for metrics
    - name: Install CLI tools (jq, sysstat, top exists)
      run: |
        sudo apt-get update
        sudo apt-get install -y jq sysstat
        mpstat -V || true

    # ---------- Collect live build & test metrics ----------
    - name: Collect build metrics
    # Optional toggle: set this in repo/Org env to get non-zero build_time
      env:
        TIMER_NO_CACHE: "${{ vars.TIMER_NO_CACHE || '0' }}"  # set to '1' to force no-cache
      id: metrics
      run: |
        set -euo pipefail

        # Build timer image (optionally no-cache to avoid 0s when cache hits)
        if [ "${TIMER_NO_CACHE}" = "1" ]; then NC="--no-cache"; else NC=""; fi
        build_start=$(date +%s)
        docker build --platform linux/amd64 $NC -t $ECR_REPO:test-timer ./app >/dev/null
        build_time=$(( $(date +%s) - build_start ))

        # Run tests & parse summary
        pytest -q | tee test.log || true
        failed=$(grep -oP '(?<= )[0-9]+(?= failed)' test.log || echo 0)
        passed=$(grep -oP '(?<= )[0-9]+(?= passed)' test.log || echo 0)
        total=$(( passed + failed ))
        if [ "$total" -eq 0 ]; then
          test_pass_rate=0
        else
          test_pass_rate=$(awk "BEGIN {printf \"%.2f\", $passed/$total}")
        fi

        # CPU usage via mpstat, robust awk; fallback to top
        cpu_usage_raw=$(mpstat 1 5 2>/dev/null | awk '/Average/ && $NF ~ /^[0-9.]+$/ {val=100-$NF} END {if (val=="") {print ""} else {printf("%.0f", val)}}')
        if [ -z "${cpu_usage_raw}" ]; then
          cpu_usage_raw=$(top -bn2 -d 0.5 | grep "Cpu(s)" | tail -1 | awk -F',' '{for(i=1;i<=NF;i++){if($i~/%id/){gsub(/[^0-9.]/,"",$i); print 100-$i}}}')
        fi
        cpu_usage=${cpu_usage_raw:-0}

        # Emit metrics JSON (only the features your model expects)
        metrics_json=$(jq -n -c \
          --arg bt "$build_time" \
          --arg ec "$failed" \
          --arg cu "$cpu_usage" \
          --arg tpr "$test_pass_rate" \
          '{build_time:($bt|tonumber),error_count:($ec|tonumber),cpu_usage:($cu|tonumber),test_pass_rate:($tpr|tonumber)}')

        echo "Metrics â†’ $metrics_json"
        echo "$metrics_json" > metrics.json
        echo "json=$metrics_json" >> $GITHUB_OUTPUT

    - name: Upload metrics artifacts
      uses: actions/upload-artifact@v4
      with:
        name: ci-metrics-${{ github.run_id }}
        path: |
          test.log
          metrics.json
    # --------------------------------------------------------

    # ---------- Predict step (early) ----------
    - name: Predict failure probability
      id: predict
      run: |
        prob=$(python ml_model/predict_failure.py --plain --input-json '${{ steps.metrics.outputs.json }}')
        echo "Predicted failure probability: $prob"
        echo "fail_prob=$prob" >> $GITHUB_OUTPUT

    # ---------- Conditional Rollout based on prediction ----------
    - name: Rollout new image
      if: ${{ steps.predict.outputs.fail_prob && fromJson(steps.predict.outputs.fail_prob) < 0.7 }}
      env:
        IMAGE_URI: "${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_DEFAULT_REGION }}.amazonaws.com/${{ env.ECR_REPO }}:${{ github.sha }}"
      run: |
        kubectl set image deployment/$DEPLOY $CTR=$IMAGE_URI -n $NS
        kubectl rollout status deployment/$DEPLOY -n $NS --timeout=180s

    - name: Autoâ€‘heal if high failure risk
      if: ${{ steps.predict.outputs.fail_prob && fromJson(steps.predict.outputs.fail_prob) >= 0.7 }}
      env:
        SLACK_WEBHOOK_URL: "${{ secrets.SLACK_WEBHOOK_URL }}"
      run: |
        python pipeline/scripts/smart_auto_heal.py --deployment $DEPLOY --namespace $NS --replicas 3
        curl -X POST -H 'Content-Type: application/json' \
             --data "{\"text\":\"ðŸš‘ Autoâ€‘heal triggered (fail_prob=${{ steps.predict.outputs.fail_prob }}).\"}" \
             "$SLACK_WEBHOOK_URL"
