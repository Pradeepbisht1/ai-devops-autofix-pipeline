name: Predict, Deploy & Auto-Heal Pipeline

on:
  workflow_dispatch:
  push:
    branches: ['main']

permissions:
  id-token: write
  contents: read

env:
  AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
  AWS_ACCOUNT_ID:     ${{ secrets.AWS_ACCOUNT_ID }}
  EKS_CLUSTER_NAME:   ${{ secrets.EKS_CLUSTER_NAME }}
  EKS_NAMESPACE:      prod

  BACKEND_REPO:       myapp
  FRONTEND_REPO:      ai-devops-frontend

  PROM_NAMESPACE:     monitoring
  PROM_SERVICE_NAME:  prometheus-operated

  BACKEND_DEPLOY:     backend
  BACKEND_CONTAINER:  backend
  BACKEND_SERVICE:    backend
  FRONTEND_DEPLOY:    frontend
  FRONTEND_CONTAINER: frontend
  FRONTEND_SERVICE:   frontend

  RISK_THRESHOLD:     "0.70"

  SELECTOR_LABEL:     app
  SELECTOR_VALUE:     backend

jobs:
  build-deploy-heal:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Verify model artifact (no external deps)
        run: |
          python3 - <<'PY'
          import os, sys
          p='ml_model/models/model.pkl'
          if not os.path.exists(p):
              print(f"Missing model file: {p}"); sys.exit(1)
          size = os.path.getsize(p)
          with open(p,'rb') as f:
              head=f.read(32)
          if head.startswith(b'version https://'):
              print("LFS POINTER DETECTED: commit real model.pkl (no LFS)"); sys.exit(1)
          if size < 1024:
              print(f"Model file too small/suspicious: {size} bytes"); sys.exit(1)
          print(f"MODEL_FILE_OK size={size} bytes")
          PY

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region:     ${{ env.AWS_DEFAULT_REGION }}

      - name: Who am I?
        run: aws sts get-caller-identity

      - name: Ensure ECR repos
        run: |
          for repo in "${BACKEND_REPO}" "${FRONTEND_REPO}"; do
            aws ecr describe-repositories --repository-names "$repo" >/dev/null 2>&1 \
              || aws ecr create-repository --repository-name "$repo"
          done

      - name: Login to ECR
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build & push backend
        env:
          IMAGE_URI: ${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_DEFAULT_REGION }}.amazonaws.com/${{ env.BACKEND_REPO }}:${{ github.sha }}
        run: |
          docker build --platform linux/amd64 -t backend:prod -f app/Dockerfile .
          docker tag backend:prod "$IMAGE_URI"
          docker push "$IMAGE_URI"
          echo "BACKEND_IMAGE=$IMAGE_URI" >> $GITHUB_ENV

      - name: Build & push frontend
        env:
          IMAGE_URI: ${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_DEFAULT_REGION }}.amazonaws.com/${{ env.FRONTEND_REPO }}:${{ github.sha }}
        run: |
          docker build --platform linux/amd64 -t frontend:prod dashboard
          docker tag frontend:prod "$IMAGE_URI"
          docker push "$IMAGE_URI"
          echo "FRONTEND_IMAGE=$IMAGE_URI" >> $GITHUB_ENV

      - name: Upload model artefact (optional)
        run: |
          if [ -f ml_model/models/model.pkl ] && [ -n "${{ secrets.MODEL_S3_PATH }}" ]; then
            aws s3 cp ml_model/models/model.pkl "${{ secrets.MODEL_S3_PATH }}"
          fi

      - name: Install kubectl
        run: |
          curl -sSL https://dl.k8s.io/release/$(curl -sSL https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl -o kubectl
          chmod +x kubectl && sudo mv kubectl /usr/local/bin

      - name: Configure kubeconfig
        run: |
          aws eks update-kubeconfig --region "${AWS_DEFAULT_REGION}" --name "${EKS_CLUSTER_NAME}"

      - name: Apply Kubernetes manifests
        run: |
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/backend-svc.yaml
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/frontend-svc.yaml
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/backend-servicemonitor.yaml || true
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/hpa-backend.yaml || true
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/hpa-frontend.yaml || true
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/ingress.yaml || true

          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/backend-deploy.yaml
          kubectl -n "${EKS_NAMESPACE}" set image deployment/${BACKEND_DEPLOY} ${BACKEND_CONTAINER}="${BACKEND_IMAGE}"

          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/frontend-deploy.yaml
          kubectl -n "${EKS_NAMESPACE}" set image deployment/${FRONTEND_DEPLOY} ${FRONTEND_CONTAINER}="${FRONTEND_IMAGE}"

      - name: Wait for backend rollout
        run: kubectl -n "${EKS_NAMESPACE}" rollout status deployment/${BACKEND_DEPLOY} --timeout=5m

      - name: Wait for frontend rollout
        run: kubectl -n "${EKS_NAMESPACE}" rollout status deployment/${FRONTEND_DEPLOY} --timeout=5m

      - name: Install jq and Python deps
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          python3 -m pip install --upgrade pip
          python3 -m pip install requests

      - name: Warm-up backend for real metrics
        run: |
          kubectl -n "${EKS_NAMESPACE}" port-forward svc/${BACKEND_SERVICE} 5000:5000 >/tmp/pf-backend.log 2>&1 &
          echo $! > /tmp/pf_backend.pid
          for i in {1..60}; do curl -sf http://127.0.0.1:5000/healthz && break || sleep 1; done
          for i in {1..300}; do
            curl -s -m 2 http://127.0.0.1:5000/predict -H 'Content-Type: application/json' \
              --data '{"restart_count_last_5m":0,"cpu_usage_pct":10,"memory_usage_bytes":5e7,"ready_replica_ratio":1,"unavailable_replicas":0,"network_receive_bytes_per_s":0,"http_5xx_error_rate":0}' >/dev/null || true
          done
          kill $(cat /tmp/pf_backend.pid) 2>/dev/null || true

      - name: Predict from runtime metrics
        id: predict
        env:
          NS:       ${{ env.EKS_NAMESPACE }}
          PROM_NS:  ${{ env.PROM_NAMESPACE }}
          PROM_SVC: ${{ env.PROM_SERVICE_NAME }}
          THRESHOLD: ${{ env.RISK_THRESHOLD }}
          SEL_LABEL: ${{ env.SELECTOR_LABEL }}
          SEL_VALUE: ${{ env.SELECTOR_VALUE }}
        shell: bash
        run: |
          set -euo pipefail

          kubectl -n "$PROM_NS" get svc "$PROM_SVC" -o name
          kubectl -n "$PROM_NS" port-forward svc/"$PROM_SVC" 9090:9090 >/tmp/pf-prom.log 2>&1 &
          echo $! > /tmp/pf_prom.pid
          trap 'kill $(cat /tmp/pf_prom.pid) 2>/dev/null || true' EXIT
          for i in {1..60}; do curl -sf http://127.0.0.1:9090/-/ready >/dev/null && break || sleep 1; done

          py() { python3 - "$@"; }

          FEATURES=$(py <<'PY'
import json, requests, os, sys

# --- Configuration from Environment Variables ---
ns = os.getenv("NS", "prod")
sel_label = os.getenv("SEL_LABEL", "app")
sel_value = os.getenv("SEL_VALUE", "backend")
backend_deploy = os.getenv("BACKEND_DEPLOY", "backend")
threshold = float(os.getenv("THRESHOLD", "0.70"))
url = "http://127.0.0.1:9090/api/v1/query"

# --- Helper function to query Prometheus and handle errors ---
def q(expr):
    try:
        r = requests.get(url, params={"query": expr}, timeout=15)
        r.raise_for_status()
        return r.json()
    except requests.exceptions.RequestException as e:
        print(f"Error querying Prometheus for '{expr}': {e}", file=sys.stderr)
        return {"data": {"result": []}}

# --- Helper to safely extract a single value from a query result ---
# Averages the values if multiple time series are returned (e.g., from multiple pods).
def val_of(js, default=0.0):
    try:
        results = js["data"]["result"]
        if not results:
            return default
        # Sum all values from the vector and average them
        total = sum(float(r["value"][1]) for r in results)
        return total / len(results)
    except (IndexError, KeyError, ValueError):
        return default

# --- Define Selectors ---
# Use a label selector on metrics, which is far more reliable.
pod_selector = f'{sel_label}="{sel_value}"'
deployment_selector = f'deployment="{backend_deploy}"'

# --- Direct Metric Queries (like in fetch_features.sh) ---
cpu_query = f'rate(container_cpu_usage_seconds_total{{namespace="{ns}", {pod_selector}}}[2m]) * 100'
cpu = val_of(q(cpu_query))

mem_query = f'avg(container_memory_usage_bytes{{namespace="{ns}", {pod_selector}}})'
mem = val_of(q(mem_query))

net_query = f'rate(container_network_receive_bytes_total{{namespace="{ns}", {pod_selector}}}[2m])'
net = val_of(q(net_query))

restarts_query = f'increase(kube_pod_container_status_restarts_total{{namespace="{ns}", {pod_selector}}}[5m])'
restarts = val_of(q(restarts_query), default=0) # increase() can be empty

# --- Deployment Status Queries ---
desired_query = f'kube_deployment_spec_replicas{{namespace="{ns}", {deployment_selector}}}'
desired = val_of(q(desired_query))

ready_query = f'kube_deployment_status_replicas_ready{{namespace="{ns}", {deployment_selector}}}'
ready = val_of(q(ready_query))

unavail_query = f'kube_deployment_status_replicas_unavailable{{namespace="{ns}", {deployment_selector}}}'
unavail = val_of(q(unavail_query))

ratio = (ready / desired) if desired > 0 else 1.0

# --- HTTP 5xx Error Rate ---
# This query assumes your http_server_errors_total metric is labeled with app="backend"
http5xx = 0.0
try:
    # Use the pod selector to filter requests for the correct app
    error_rate_query = f'sum(rate(http_server_errors_total{{namespace="{ns}", {pod_selector}}}[2m]))'
    http5xx = val_of(q(error_rate_query))
except Exception:
    pass

# --- Final JSON Output ---
feats = {
    "restart_count_last_5m": restarts,
    "cpu_usage_pct": cpu,
    "memory_usage_bytes": mem,
    "ready_replica_ratio": round(ratio, 4),
    "unavailable_replicas": unavail,
    "network_receive_bytes_per_s": net,
    "http_5xx_error_rate": http5xx,
}

print(json.dumps(feats))
PY
          )

          echo "Features: $FEATURES"

          kubectl -n "${NS}" port-forward svc/${BACKEND_SERVICE} 5000:5000 >/tmp/pf-backend2.log 2>&1 &
          echo $! > /tmp/pf_backend2.pid
          for i in {1..60}; do curl -sf http://127.0.0.1:5000/healthz >/dev/null && break || sleep 1; done

          RESP=$(curl -s -X POST http://127.0.0.1:5000/predict \
                   -H "Content-Type: application/json" -d "${FEATURES}")
          echo "Predict: $RESP"

          PROB=$(echo "$RESP" | sed -n 's/.*"probability":\s*\([0-9.]*\).*/\1/p'); : ${PROB:=0}
          LOADED=$(echo "$RESP" | grep -o '"model_loaded":[^,}]*' | cut -d: -f2 | tr -d ' ')

          echo "fail_prob=$PROB" >> $GITHUB_OUTPUT
          echo "model_loaded=${LOADED:-false}" >> $GITHUB_OUTPUT

          if [ "${LOADED:-false}" = "true" ] && awk -v p="$PROB" -v thr="${THRESHOLD}" 'BEGIN{exit !(p>=thr)}'; then
            echo "highrisk=true"  >> $GITHUB_OUTPUT
          else
            echo "highrisk=false" >> $GITHUB_OUTPUT
          fi

          kill $(cat /tmp/pf_backend2.pid) 2>/dev/null || true

      - name: Auto-heal (rollout restart)
        if: ${{ steps.predict.outputs.highrisk == 'true' && steps.predict.outputs.model_loaded == 'true' }}
        run: |
          kubectl -n "${EKS_NAMESPACE}" rollout restart deployment/${BACKEND_DEPLOY}
          kubectl -n "${EKS_NAMESPACE}" rollout status deployment/${BACKEND_DEPLOY} --timeout=5m

      - name: Re-check risk after heal
        id: recheck
        if: ${{ steps.predict.outputs.highrisk == 'true' }}
        env:
          NS:       ${{ env.EKS_NAMESPACE }}
          PROM_NS:  ${{ env.PROM_NAMESPACE }}
          PROM_SVC: ${{ env.PROM_SERVICE_NAME }}
          THRESHOLD: ${{ env.RISK_THRESHOLD }}
          SEL_LABEL: ${{ env.SELECTOR_LABEL }}
          SEL_VALUE: ${{ env.SELECTOR_VALUE }}
        shell: bash
        run: |
          set -euo pipefail
          sleep 60

          kubectl -n "$PROM_NS" port-forward svc/"$PROM_SVC" 9090:9090 >/tmp/pf-prom2.log 2>&1 &
          echo $! > /tmp/pf_prom2.pid
          trap 'kill $(cat /tmp/pf_prom2.pid) 2>/dev/null || true' EXIT
          for i in {1..60}; do curl -sf http://127.0.0.1:9090/-/ready >/dev/null && break || sleep 1; done

          FEATURES=$(python3 - <<'PY'
import json, requests, os, sys

# --- Configuration from Environment Variables ---
ns = os.getenv("NS", "prod")
sel_label = os.getenv("SEL_LABEL", "app")
sel_value = os.getenv("SEL_VALUE", "backend")
backend_deploy = os.getenv("BACKEND_DEPLOY", "backend")
threshold = float(os.getenv("THRESHOLD", "0.70"))
url = "http://127.0.0.1:9090/api/v1/query"

# --- Helper function to query Prometheus and handle errors ---
def q(expr):
    try:
        r = requests.get(url, params={"query": expr}, timeout=15)
        r.raise_for_status()
        return r.json()
    except requests.exceptions.RequestException as e:
        print(f"Error querying Prometheus for '{expr}': {e}", file=sys.stderr)
        return {"data": {"result": []}}

# --- Helper to safely extract a single value from a query result ---
# Averages the values if multiple time series are returned (e.g., from multiple pods).
def val_of(js, default=0.0):
    try:
        results = js["data"]["result"]
        if not results:
            return default
        # Sum all values from the vector and average them
        total = sum(float(r["value"][1]) for r in results)
        return total / len(results)
    except (IndexError, KeyError, ValueError):
        return default

# --- Define Selectors ---
# Use a label selector on metrics, which is far more reliable.
pod_selector = f'{sel_label}="{sel_value}"'
deployment_selector = f'deployment="{backend_deploy}"'

# --- Direct Metric Queries (like in fetch_features.sh) ---
cpu_query = f'rate(container_cpu_usage_seconds_total{{namespace="{ns}", {pod_selector}}}[2m]) * 100'
cpu = val_of(q(cpu_query))

mem_query = f'avg(container_memory_usage_bytes{{namespace="{ns}", {pod_selector}}})'
mem = val_of(q(mem_query))

net_query = f'rate(container_network_receive_bytes_total{{namespace="{ns}", {pod_selector}}}[2m])'
net = val_of(q(net_query))

restarts_query = f'increase(kube_pod_container_status_restarts_total{{namespace="{ns}", {pod_selector}}}[5m])'
restarts = val_of(q(restarts_query), default=0) # increase() can be empty

# --- Deployment Status Queries ---
desired_query = f'kube_deployment_spec_replicas{{namespace="{ns}", {deployment_selector}}}'
desired = val_of(q(desired_query))

ready_query = f'kube_deployment_status_replicas_ready{{namespace="{ns}", {deployment_selector}}}'
ready = val_of(q(ready_query))

unavail_query = f'kube_deployment_status_replicas_unavailable{{namespace="{ns}", {deployment_selector}}}'
unavail = val_of(q(unavail_query))

ratio = (ready / desired) if desired > 0 else 1.0

# --- HTTP 5xx Error Rate ---
# This query assumes your http_server_errors_total metric is labeled with app="backend"
http5xx = 0.0
try:
    # Use the pod selector to filter requests for the correct app
    error_rate_query = f'sum(rate(http_server_errors_total{{namespace="{ns}", {pod_selector}}}[2m]))'
    http5xx = val_of(q(error_rate_query))
except Exception:
    pass

# --- Final JSON Output ---
feats = {
    "restart_count_last_5m": restarts,
    "cpu_usage_pct": cpu,
    "memory_usage_bytes": mem,
    "ready_replica_ratio": round(ratio, 4),
    "unavailable_replicas": unavail,
    "network_receive_bytes_per_s": net,
    "http_5xx_error_rate": http5xx,
}

print(json.dumps(feats))
PY
          )

          kubectl -n "${NS}" port-forward svc/${BACKEND_SERVICE} 5000:5000 >/tmp/pf-backend3.log 2>&1 &
          echo $! > /tmp/pf_backend3.pid
          for i in {1..60}; do curl -sf http://127.0.0.1:5000/healthz >/dev/null && break || sleep 1; done

          RESP=$(curl -s -X POST http://127.0.0.1:5000/predict \
                   -H "Content-Type: application/json" -d "${FEATURES}")
          PROB=$(echo "$RESP" | sed -n 's/.*"probability":\s*\([0-9.]*\).*/\1/p'); : ${PROB:=0}
          echo "fail_prob2=$PROB" >> $GITHUB_OUTPUT

          kill $(cat /tmp/pf_backend3.pid) 2>/dev/null || true

          awk -v p="$PROB" -v thr="${THRESHOLD}" 'BEGIN{exit !(p>=thr)}' \
            && echo "still_high=true"  >> $GITHUB_OUTPUT \
            || echo "still_high=false" >> $GITHUB_OUTPUT

      - name: Rollback if still high
        if: ${{ steps.recheck.outputs.still_high == 'true' }}
        run: |
          kubectl -n "${EKS_NAMESPACE}" rollout undo deployment/${BACKEND_DEPLOY}

      - name: Slack alert (high → healed)
        if: ${{ steps.predict.outputs.highrisk == 'true' && steps.recheck.outputs.still_high != 'true' }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          if [ -n "${SLACK_WEBHOOK_URL:-}" ]; then
            msg="⚠️ High risk (p=${{ steps.predict.outputs.fail_prob }}) on ${BACKEND_DEPLOY}. Auto-heal applied."
            printf '%s\n' "$msg" | jq -Rs '{text: .}' | curl -sS -X POST -H 'Content-Type: application/json' --data @- "$SLACK_WEBHOOK_URL"
          fi

      - name: Slack alert (rolled back)
        if: ${{ steps.recheck.outputs.still_high == 'true' }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          if [ -n "${SLACK_WEBHOOK_URL:-}" ]; then
            msg="⚠️ Risk persisted (p=${{ steps.recheck.outputs.fail_prob2 }}) → rolled back ${BACKEND_DEPLOY}."
            printf '%s\n' "$msg" | jq -Rs '{text: .}' | curl -sS -X POST -H 'Content-Type: application/json' --data @- "$SLACK_WEBHOOK_URL"
          fi

      - name: Slack success (kept)
        if: ${{ steps.predict.outputs.highrisk != 'true' }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          if [ -n "${SLACK_WEBHOOK_URL:-}" ]; then
            msg="✅ Rollout kept. Risk p=${{ steps.predict.outputs.fail_prob }}."
            printf '%s\n' "$msg" | jq -Rs '{text: .}' | curl -sS -X POST -H 'Content-Type: application/json' --data @- "$SLACK_WEBHOOK_URL"
          fi
