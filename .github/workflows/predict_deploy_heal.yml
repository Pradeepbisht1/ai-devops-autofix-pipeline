name: Predict, Deploy & Auto-Heal Pipeline

on:
  workflow_dispatch:
  push:
    branches: ['main']

permissions:
  id-token: write
  contents: read

env:
  AWS_DEFAULT_REGION:  ${{ secrets.AWS_DEFAULT_REGION }}
  AWS_ACCOUNT_ID:      ${{ secrets.AWS_ACCOUNT_ID }}
  EKS_CLUSTER_NAME:    ${{ secrets.EKS_CLUSTER_NAME }}
  EKS_NAMESPACE:       ${{ secrets.EKS_NAMESPACE || 'ai-devops' }}

  # ECR repos (do alag)
  BACKEND_REPO:        myapp
  FRONTEND_REPO:       ai-devops-frontend

  # Prometheus service (kube-prometheus-stack install hone ke baad verify karo)
  PROM_NAMESPACE:      monitoring
  PROM_SERVICE_NAME:   kube-prometheus-stack-prometheus   # `kubectl -n monitoring get svc` se confirm

  # K8s naming (manifests ke labels/names ke saath match rakho)
  BACKEND_DEPLOY:      backend
  BACKEND_CONTAINER:   backend
  BACKEND_SERVICE:     backend           # ClusterIP svc on port 5000
  FRONTEND_DEPLOY:     frontend
  FRONTEND_CONTAINER:  frontend
  FRONTEND_SERVICE:    frontend          # LB/Ingress svc on port 80

  RISK_THRESHOLD:      "0.70"

jobs:
  build-deploy-heal:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      # ---------- AWS auth (OIDC role preferred) ----------
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region:     ${{ env.AWS_DEFAULT_REGION }}

      - name: Who am I?
        run: aws sts get-caller-identity

      # ---------- Ensure ECR repos exist ----------
      - name: Ensure ECR repos
        run: |
          for repo in "${BACKEND_REPO}" "${FRONTEND_REPO}"; do
            aws ecr describe-repositories --repository-names "$repo" >/dev/null 2>&1 \
              || aws ecr create-repository --repository-name "$repo"
          done

      - name: Login to ECR
        uses: aws-actions/amazon-ecr-login@v2

      # ---------- Build & push BACKEND image ----------
      - name: Build & push backend
        env:
          IMAGE_URI: ${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_DEFAULT_REGION }}.amazonaws.com/${{ env.BACKEND_REPO }}:${{ github.sha }}
        run: |
          docker build --platform linux/amd64 -t backend:prod -f app/Dockerfile .
          docker tag backend:prod "$IMAGE_URI"
          docker push "$IMAGE_URI"
          echo "BACKEND_IMAGE=$IMAGE_URI" >> $GITHUB_ENV

      # ---------- Build & push FRONTEND image ----------
      - name: Build & push frontend
        env:
          IMAGE_URI: ${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_DEFAULT_REGION }}.amazonaws.com/${{ env.FRONTEND_REPO }}:${{ github.sha }}
        run: |
          docker build --platform linux/amd64 -t frontend:prod dashboard
          docker tag frontend:prod "$IMAGE_URI"
          docker push "$IMAGE_URI"
          echo "FRONTEND_IMAGE=$IMAGE_URI" >> $GITHUB_ENV

      # (Optional) model artifact to S3 (if you keep external copy)
      - name: Upload model artefact (optional)
        run: |
          if [ -f ml_model/models/model.pkl ] && [ -n "${{ secrets.MODEL_S3_PATH }}" ]; then
            aws s3 cp ml_model/models/model.pkl "${{ secrets.MODEL_S3_PATH }}"
          fi

      # ---------- kubectl ----------
      - name: Install kubectl
        run: |
          curl -sSL https://dl.k8s.io/release/$(curl -sSL https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl -o kubectl
          chmod +x kubectl && sudo mv kubectl /usr/local/bin

      - name: Configure kubeconfig
        run: |
          aws eks update-kubeconfig --region "${AWS_DEFAULT_REGION}" --name "${EKS_CLUSTER_NAME}"
          kubectl get ns "${EKS_NAMESPACE}" >/dev/null 2>&1 || kubectl create ns "${EKS_NAMESPACE}"

      # ---------- Apply manifests (backend, frontend, svc, ingress, hpa, servicemonitor) ----------
      - name: Apply Kubernetes manifests
        run: |
          # Replace placeholders in images directly via kubectl set image
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/namespace.yaml || true
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/backend-svc.yaml
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/frontend-svc.yaml
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/backend-servicemonitor.yaml || true
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/hpa-backend.yaml || true
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/hpa-frontend.yaml || true
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/ingress.yaml || true

          # Deployments (apply first, then set image to our freshly built SHAs)
          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/backend-deploy.yaml
          kubectl -n "${EKS_NAMESPACE}" set image deployment/${BACKEND_DEPLOY} ${BACKEND_CONTAINER}="${BACKEND_IMAGE}"

          kubectl -n "${EKS_NAMESPACE}" apply -f kubernetes/frontend-deploy.yaml
          kubectl -n "${EKS_NAMESPACE}" set image deployment/${FRONTEND_DEPLOY} ${FRONTEND_CONTAINER}="${FRONTEND_IMAGE}"

      # ---------- Wait for rollout ----------
      - name: Wait for backend rollout
        run: kubectl -n "${EKS_NAMESPACE}" rollout status deployment/${BACKEND_DEPLOY} --timeout=5m

      - name: Wait for frontend rollout
        run: kubectl -n "${EKS_NAMESPACE}" rollout status deployment/${FRONTEND_DEPLOY} --timeout=5m

      # ---------- Warm-up backend (optional) ----------
      - name: Warm-up backend for real metrics
        run: |
          # Port-forward backend service (5000)
          kubectl -n "${EKS_NAMESPACE}" port-forward svc/${BACKEND_SERVICE} 5000:5000 >/tmp/pf-backend.log 2>&1 &
          echo $! > /tmp/pf_backend.pid
          for i in {1..60}; do curl -sf http://127.0.0.1:5000/healthz && break || sleep 1; done
          # 300 quick hits to generate CPU/Net
          for i in {1..300}; do
            curl -s -m 2 http://127.0.0.1:5000/predict -H 'Content-Type: application/json' \
              --data '{"restart_count_last_5m":0,"cpu_usage_pct":10,"memory_usage_bytes":5e7,"ready_replica_ratio":1,"unavailable_replicas":0,"network_receive_bytes_per_s":0,"http_5xx_error_rate":0}' >/dev/null || true
          done
          kill $(cat /tmp/pf_backend.pid) 2>/dev/null || true

      # ---------- Query Prometheus (7 features) & call /predict ----------
      - name: Predict from runtime metrics
        id: predict
        env:
          NS:  ${{ env.EKS_NAMESPACE }}
          DEP: ${{ env.BACKEND_DEPLOY }}
          PROM_NS:  ${{ env.PROM_NAMESPACE }}
          PROM_SVC: ${{ env.PROM_SERVICE_NAME }}
          THRESHOLD: ${{ env.RISK_THRESHOLD }}
        shell: bash
        run: |
          set -euo pipefail

          # PF Prometheus
          kubectl -n "$PROM_NS" get svc "$PROM_SVC" -o name
          kubectl -n "$PROM_NS" port-forward svc/"$PROM_SVC" 9090:9090 >/tmp/pf-prom.log 2>&1 &
          echo $! > /tmp/pf_prom.pid
          trap 'kill $(cat /tmp/pf_prom.pid) 2>/dev/null || true' EXIT
          for i in {1..60}; do curl -sf http://127.0.0.1:9090/-/ready >/dev/null && break || sleep 1; done

          py() { python - "$@"; }

          FEATURES=$(py <<'PY'
          import json,requests,os,sys,time
          ns=os.getenv("NS"); dep=os.getenv("DEP")
          url="http://127.0.0.1:9090/api/v1/query"
          def q(e):
              r=requests.get(url,params={'query':e},timeout=10); r.raise_for_status(); return r.json()
          def val(js):
              try: return float(js['data']['result'][0]['value'][1])
              except: return 0.0
          # Selector join towards deployment
          join = f'* on(pod,namespace) group_left(owner_kind,owner_name) kube_pod_owner{{namespace="{ns}",owner_kind="Deployment",owner_name="{dep}"}}'
          # 7 features
          restarts = val(q(f'sum(increase(kube_pod_container_status_restarts_total{{namespace="{ns}"}}[5m]) {join})'))
          cpu      = val(q(f'sum(rate(container_cpu_usage_seconds_total{{namespace="{ns}",container!="POD",image!=""}}[2m]) {join}) * 100'))
          mem      = val(q(f'sum(container_memory_working_set_bytes{{namespace="{ns}",container!="POD",image!=""}} {join})'))
          des      = val(q(f'kube_deployment_spec_replicas{{namespace="{ns}",deployment="{dep}"}}'))
          rdy      = val(q(f'kube_deployment_status_ready_replicas{{namespace="{ns}",deployment="{dep}"}}'))
          ready_ratio = (rdy/des) if des>0 else 1.0
          unavail  = val(q(f'kube_deployment_status_replicas_unavailable{{namespace="{ns}",deployment="{dep}"}}'))
          net_rx   = val(q(f'sum(rate(container_network_receive_bytes_total{{namespace="{ns}",pod!=""}}[2m]) {join})'))
          # backend counter name variants
          http5xx  = 0.0
          for e in [
            f'sum(rate(http_request_total{{status=~"5.."}}[2m]))/sum(rate(http_request_total[2m]))',
            f'sum(rate(http_requests_total{{code=~"5.."}}[2m]))/sum(rate(http_requests_total[2m]))',
            f'sum(rate(flask_http_request_total{{status=~"5.."}}[2m]))/sum(rate(flask_http_request_total[2m]))'
          ]:
              try:
                  v=val(q(e))
                  if v>0: http5xx=v; break
              except: pass
          feats={
            "restart_count_last_5m":restarts,
            "cpu_usage_pct":cpu,
            "memory_usage_bytes":mem,
            "ready_replica_ratio":round(ready_ratio,4),
            "unavailable_replicas":unavail,
            "network_receive_bytes_per_s":net_rx,
            "http_5xx_error_rate":http5xx
          }
          print(json.dumps(feats))
          PY
          )

          echo "Features: $FEATURES"

          # Call backend /predict via PF
          kubectl -n "${NS}" port-forward svc/${DEP} 5000:5000 >/tmp/pf-backend2.log 2>&1 &
          echo $! > /tmp/pf_backend2.pid
          for i in {1..60}; do curl -sf http://127.0.0.1:5000/healthz >/dev/null && break || sleep 1; done

          RESP=$(curl -s -X POST http://127.0.0.1:5000/predict \
                -H "Content-Type: application/json" -d "${FEATURES}")
          echo "Predict: $RESP"
          PROB=$(echo "$RESP" | sed -n 's/.*"probability":\s*\([0-9.]*\).*/\1/p')
          : ${PROB:=0}

          kill $(cat /tmp/pf_backend2.pid) 2>/dev/null || true

          echo "fail_prob=$PROB" >> $GITHUB_OUTPUT

          awk -v p="$PROB" -v thr="${THRESHOLD}" 'BEGIN{exit !(p>=thr)}' \
            && echo "highrisk=true"  >> $GITHUB_OUTPUT \
            || echo "highrisk=false" >> $GITHUB_OUTPUT

      # ---------- Auto-heal (restart) if high risk ----------
      - name: Auto-heal (rollout restart)
        if: ${{ steps.predict.outputs.highrisk == 'true' }}
        run: |
          kubectl -n "${EKS_NAMESPACE}" rollout restart deployment/${BACKEND_DEPLOY}
          kubectl -n "${EKS_NAMESPACE}" rollout status  deployment/${BACKEND_DEPLOY} --timeout=5m

      # ---------- Re-check after heal; rollback if still high ----------
      - name: Re-check risk after heal
        id: recheck
        if: ${{ steps.predict.outputs.highrisk == 'true' }}
        env:
          NS:  ${{ env.EKS_NAMESPACE }}
          DEP: ${{ env.BACKEND_DEPLOY }}
          PROM_NS:  ${{ env.PROM_NAMESPACE }}
          PROM_SVC: ${{ env.PROM_SERVICE_NAME }}
          THRESHOLD: ${{ env.RISK_THRESHOLD }}
        run: |
          set -euo pipefail
          # quick cool-down
          sleep 60

          # PF prom
          kubectl -n "$PROM_NS" port-forward svc/"$PROM_SVC" 9090:9090 >/tmp/pf-prom2.log 2>&1 &
          echo $! > /tmp/pf_prom2.pid
          trap 'kill $(cat /tmp/pf_prom2.pid) 2>/dev/null || true' EXIT
          for i in {1..60}; do curl -sf http://127.0.0.1:9090/-/ready >/dev/null && break || sleep 1; done

          # (same Python as before, compacted)
          FEATURES=$(python - <<'PY'
          import json,requests,os
          ns=os.getenv("NS"); dep=os.getenv("DEP"); url="http://127.0.0.1:9090/api/v1/query"
          def q(e): return requests.get(url,params={'query':e},timeout=10).json()
          def val(js):
              try: return float(js['data']['result'][0]['value'][1])
              except: return 0.0
          join=f'* on(pod,namespace) group_left(owner_kind,owner_name) kube_pod_owner{{namespace="{ns}",owner_kind="Deployment",owner_name="{dep}"}}'
          restarts=val(q(f'sum(increase(kube_pod_container_status_restarts_total{{namespace="{ns}"}}[5m]) {join})'))
          cpu=val(q(f'sum(rate(container_cpu_usage_seconds_total{{namespace="{ns}",container!="POD",image!=""}}[2m]) {join}) * 100'))
          mem=val(q(f'sum(container_memory_working_set_bytes{{namespace="{ns}",container!="POD",image!=""}} {join})'))
          des=val(q(f'kube_deployment_spec_replicas{{namespace="{ns}",deployment="{dep}"}}'))
          rdy=val(q(f'kube_deployment_status_ready_replicas{{namespace="{ns}",deployment="{dep}"}}'))
          ready_ratio=(rdy/des) if des>0 else 1.0
          unavail=val(q(f'kube_deployment_status_replicas_unavailable{{namespace="{ns}",deployment="{dep}"}}'))
          net_rx=val(q(f'sum(rate(container_network_receive_bytes_total{{namespace="{ns}",pod!=""}}[2m]) {join})'))
          http5xx=0.0
          for e in [
            f'sum(rate(http_request_total{{status=~"5.."}}[2m]))/sum(rate(http_request_total[2m]))',
            f'sum(rate(http_requests_total{{code=~"5.."}}[2m]))/sum(rate(http_requests_total[2m]))',
            f'sum(rate(flask_http_request_total{{status=~"5.."}}[2m]))/sum(rate(flask_http_request_total[2m]))'
          ]:
              try:
                  v=val(q(e))
                  if v>0: http5xx=v; break
              except: pass
          print(json.dumps({
            "restart_count_last_5m":restarts,
            "cpu_usage_pct":cpu,
            "memory_usage_bytes":mem,
            "ready_replica_ratio":round(ready_ratio,4),
            "unavailable_replicas":unavail,
            "network_receive_bytes_per_s":net_rx,
            "http_5xx_error_rate":http5xx
          }))
          PY
          )

          # call /predict again
          kubectl -n "${NS}" port-forward svc/${DEP} 5000:5000 >/tmp/pf-backend3.log 2>&1 &
          echo $! > /tmp/pf_backend3.pid
          for i in {1..60}; do curl -sf http://127.0.0.1:5000/healthz >/dev/null && break || sleep 1; done

          RESP=$(curl -s -X POST http://127.0.0.1:5000/predict \
                -H "Content-Type: application/json" -d "${FEATURES}")
          PROB=$(echo "$RESP" | sed -n 's/.*"probability":\s*\([0-9.]*\).*/\1/p'); : ${PROB:=0}
          echo "fail_prob2=$PROB" >> $GITHUB_OUTPUT

          kill $(cat /tmp/pf_backend3.pid) 2>/dev/null || true

          awk -v p="$PROB" -v thr="${THRESHOLD}" 'BEGIN{exit !(p>=thr)}' \
            && echo "still_high=true"  >> $GITHUB_OUTPUT \
            || echo "still_high=false" >> $GITHUB_OUTPUT

      - name: Rollback if still high
        if: ${{ steps.recheck.outputs.still_high == 'true' }}
        run: |
          kubectl -n "${EKS_NAMESPACE}" rollout undo deployment/${BACKEND_DEPLOY}

      # ---------- Slack notifications ----------
      - name: Slack alert (high → healed)
        if: ${{ steps.predict.outputs.highrisk == 'true' && steps.recheck.outputs.still_high != 'true' }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          if [ -n "${SLACK_WEBHOOK_URL:-}" ]; then
            msg="⚠️ High risk (p=${{ steps.predict.outputs.fail_prob }}) on ${BACKEND_DEPLOY}. Auto-heal applied."
            printf '%s\n' "$msg" | jq -Rs '{text: .}' \
              | curl -sS -X POST -H 'Content-Type: application/json' --data @- "$SLACK_WEBHOOK_URL"
          fi

      - name: Slack alert (rolled back)
        if: ${{ steps.recheck.outputs.still_high == 'true' }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          if [ -n "${SLACK_WEBHOOK_URL:-}" ]; then
            msg="🚨 Risk persisted (p=${{ steps.recheck.outputs.fail_prob2 }}) → rolled back ${BACKEND_DEPLOY}."
            printf '%s\n' "$msg" | jq -Rs '{text: .}' \
              | curl -sS -X POST -H 'Content-Type: application/json' --data @- "$SLACK_WEBHOOK_URL"
          fi

      - name: Slack success (kept)
        if: ${{ steps.predict.outputs.highrisk != 'true' }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          if [ -n "${SLACK_WEBHOOK_URL:-}" ]; then
            msg=" Rollout kept. Risk p=${{ steps.predict.outputs.fail_prob }}."
            printf '%s\n' "$msg" | jq -Rs '{text: .}' \
              | curl -sS -X POST -H 'Content-Type: application/json' --data @- "$SLACK_WEBHOOK_URL"
          fi
