name: Predict, Deploy & Autoâ€‘Heal Pipeline

on:
  workflow_dispatch:
  push:
    branches: ['*']

permissions:
  id-token: write
  contents: read

env:
  AWS_DEFAULT_REGION: "${{ secrets.AWS_DEFAULT_REGION }}"
  AWS_ACCOUNT_ID:     "${{ secrets.AWS_ACCOUNT_ID }}"
  ECR_REPO:           "${{ secrets.ECR_REPO }}"
  IMAGE_TAG:          "1.2-1-cpu-py3"
  MODEL_IMAGE_URI:    "709825985650.dkr.ecr.ap-southeast-2.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3"
  MODEL_S3_PATH:      "${{ secrets.MODEL_S3_PATH }}"

jobs:
  build-deploy-heal:
    runs-on: ubuntu-latest
    env:
      NS:     "${{ secrets.EKS_NAMESPACE        || 'prod' }}"
      DEPLOY: "${{ secrets.EKS_DEPLOYMENT_NAME  || 'my-api-deployment' }}"
      CTR:    "${{ secrets.EKS_CONTAINER_NAME   || 'api-container' }}"

    steps:
    - uses: actions/checkout@v3

    - uses: aws-actions/configure-aws-credentials@v2
      with:
        role-to-assume: "${{ secrets.AWS_ROLE_ARN }}"
        aws-region:     "${{ env.AWS_DEFAULT_REGION }}"

    - name: Who am I?
      run: aws sts get-caller-identity

    - name: Ensure ECR repos
      run: |
        for repo in "$ECR_REPO" sklearn-inference ; do
          aws ecr describe-repositories --repository-names "$repo" ||
          aws ecr create-repository --repository-name "$repo"
        done

    - name: Build & push APP image
      id: build
      env: { DOCKER_BUILDKIT: 1 }
      run: |
        build_start=$SECONDS

        docker build --platform linux/amd64 -t $ECR_REPO:${{ github.sha }} ./app
        docker tag  $ECR_REPO:${{ github.sha }} \
          $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$ECR_REPO:${{ github.sha }}
        aws ecr get-login-password --region $AWS_DEFAULT_REGION | \
          docker login -u AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
        docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$ECR_REPO:${{ github.sha }}

        echo "build_time=$(( SECONDS - build_start ))" >> $GITHUB_OUTPUT

    - name: Upload model artefact
      run: aws s3 cp ml_model/models/model.tar.gz "$MODEL_S3_PATH"

    - name: Install kubectl
      run: |
        curl -sSL https://dl.k8s.io/release/$(curl -sSL https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl -o kubectl
        chmod +x kubectl && sudo mv kubectl /usr/local/bin

    - name: Configure kubeconfig
      run: |
        aws eks update-kubeconfig --region $AWS_DEFAULT_REGION --name "${{ secrets.EKS_CLUSTER_NAME }}"
        kubectl get nodes

    - name: Bootstrap objects once
      run: kubectl apply -f kubernetes/bootstrap.yaml || true

    - name: Rollout new image
      env:
        IMAGE_URI: "${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_DEFAULT_REGION }}.amazonaws.com/${{ env.ECR_REPO }}:${{ github.sha }}"
      run: |
        kubectl set image deployment/$DEPLOY $CTR=$IMAGE_URI -n $NS
        kubectl rollout status deployment/$DEPLOY -n $NS --timeout=180s

    - uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install Python deps
      run: |
        if [[ -f requirements.txt ]]; then pip install -r requirements.txt; fi
        pip install requests pytest jq sysstat

    # ---------- Run unitâ€‘tests & gather quality metrics ----------
    - name: Run tests and capture stats
      id: tests
      run: |
        test_start=$SECONDS
        pytest -q | tee test.log
        elapsed=$(( SECONDS - test_start ))

        passed=$(grep -oP "(?<= )[0-9]+(?= passed)" test.log || echo 0)
        failed=$(grep -oP "(?<= )[0-9]+(?= failed)" test.log || echo 0)
        errors=$(grep -oP "(?<= )[0-9]+(?= error)"  test.log || echo 0)
        total=$(( passed + failed + errors ))
        pass_rate=$(python - <<PY
import sys,math; p=int(sys.argv[1]); t=int(sys.argv[2]); print(round(p/(t or 1),2))
PY $passed $total)

        echo "error_count=$errors"       >> $GITHUB_OUTPUT
        echo "test_pass_rate=$pass_rate" >> $GITHUB_OUTPUT

    # ---------- Compute average CPU during build & tests ----------
    - name: Compute average CPU usage
      id: cpu
      run: |
        # install mpstat (part of sysstat)
        mpstat 1 5 > cpu.txt
        avg_idle=$(awk '/Average/ {print $NF}' cpu.txt | tail -1)
        cpu_usage=$(printf '%.0f' "$(echo "100-$avg_idle" | bc -l)")
        echo "cpu_usage=$cpu_usage" >> $GITHUB_OUTPUT

    # ---------- Collect all live metrics ----------
    - name: Collect build metrics
      id: metrics
      run: |
        build_time=${{ steps.build.outputs.build_time }}
        error_count=${{ steps.tests.outputs.error_count }}
        cpu_usage=${{ steps.cpu.outputs.cpu_usage }}
        test_pass_rate=${{ steps.tests.outputs.test_pass_rate }}

        metrics_json=$(jq -n -c --arg bt "$build_time" --arg ec "$error_count" --arg cu "$cpu_usage" --arg tpr "$test_pass_rate" \
          '{build_time:($bt|tonumber),error_count:($ec|tonumber),cpu_usage:($cu|tonumber),test_pass_rate:($tpr|tonumber)}')

        echo "Metrics â†’ $metrics_json"
        echo "json=$metrics_json" >> $GITHUB_OUTPUT

    # ---------- Predict step ----------
    - name: Predict failure probability
      id: predict
      run: |
        prob=$(python ml_model/predict_failure.py --plain --input-json '${{ steps.metrics.outputs.json }}')
        echo "Predicted failure probability: $prob"
        echo "fail_prob=$prob" >> $GITHUB_OUTPUT

    # ---------- Autoâ€‘heal ----------
    - name: Autoâ€‘heal if prob â‰¥ 0.75
      if: "${{ steps.predict.outputs.fail_prob != '' && fromJson(steps.predict.outputs.fail_prob) >= 0.75 }}"
      env:
        SLACK_WEBHOOK_URL: "${{ secrets.SLACK_WEBHOOK_URL }}"
      run: |
        python pipeline/scripts/smart_auto_heal.py --deployment $DEPLOY --namespace $NS --replicas 3
        curl -X POST -H 'Content-Type: application/json' \
             --data "{\"text\":\"ðŸš‘ Autoâ€‘heal triggered (fail_prob=${{ steps.predict.outputs.fail_prob }}).\"}" \
             "$SLACK_WEBHOOK_URL"
